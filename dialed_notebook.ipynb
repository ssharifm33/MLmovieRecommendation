{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# Load the dataset in the same way as the main problem \n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "        load_train_valid_test_datasets()\n",
    "\n",
    "users_df = pd.read_csv('../data_movie_lens_100k/user_info.csv')\n",
    "movies_df = pd.read_csv('../data_movie_lens_100k/movie_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6422147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_to_surprise_dataset(tupl):\n",
    "    \"\"\"\n",
    "    This function convert a subset in the tuple form to a `surprise` dataset. \n",
    "    \"\"\"\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f171753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x119c7bf10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build SVD\n",
    "trainset = tuple_to_surprise_dataset(train_tuple).build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7a7ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 100)\n",
      "(1626, 100)\n"
     ]
    }
   ],
   "source": [
    "print(algo.pu.shape)\n",
    "print(algo.qi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90b26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"pseudocode\", courtesy of Liping\n",
    "def run_test(pair):\n",
    "\n",
    "    [i, j] = pair\n",
    "    try:\n",
    "        u_features = algo.pu[trainset.to_inner_uid(i)] \n",
    "    except ValueError:\n",
    "        u_features = np.zeros(100)\n",
    "\n",
    "\n",
    "    try:\n",
    "        i_features = algo.qi[trainset.to_inner_iid(j)]\n",
    "    except ValueError:\n",
    "        i_features = np.zeros(100)\n",
    "\n",
    "    user_data = users_df.loc[users_df['user_id'] == i]\n",
    "    user_metadata = np.array([user_data['age'].iloc[0], user_data['is_male'].iloc[0]])\n",
    "    item_metadata = np.array([movies_df.loc[movies_df['item_id'] == j, 'release_year'].iloc[0]])\n",
    "\n",
    "    return np.concatenate([u_features, i_features, user_metadata, item_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354edf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data_movie_lens_100k/ratings_all_development_set.csv')\n",
    "# Convert DataFrame to list of tuples\n",
    "train_pairs = list(train_df.itertuples(index=False, name=None))\n",
    "new_train_pairs = []\n",
    "\n",
    "ratings = []\n",
    "\n",
    "for pair in train_pairs:\n",
    "    new_train_pairs.append([pair[0], pair[1]])\n",
    "    ratings.append(pair[2])\n",
    "\n",
    "total_df = np.empty((89992, 203))\n",
    "\n",
    "for i, pair in enumerate(new_train_pairs):\n",
    "   total_df[i] = run_test(pair)\n",
    "\n",
    "y_vals = []\n",
    "\n",
    "for r in ratings:\n",
    "    y_vals.append(r > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee733a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression(max_iter=1000)\n",
    "# clf.fit(total_df, y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f539a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Assuming total_df is your feature matrix and y_vals are your labels\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(total_df, y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c510e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Assuming total_df is your feature matrix and y_vals are your labels, which are binary\n",
    "# y_vals are set to True if the rating is greater than 4, and False otherwise\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# .53 accuracy\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(total_df, y_vals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450b9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using pandas\n",
    "test_df = pd.read_csv('../data_movie_lens_100k/ratings_masked_leaderboard_set.csv')\n",
    "# Convert DataFrame to list of tuples\n",
    "test_pairs = list(test_df.itertuples(index=False, name=None))\n",
    "\n",
    "\n",
    "new_test_pairs = []\n",
    "\n",
    "for pair in test_pairs:\n",
    "    new_test_pairs.append([pair[0], pair[1]])\n",
    "\n",
    "test_df = np.empty((10000, 203))\n",
    "\n",
    "\n",
    "for i, pair in enumerate(new_test_pairs):\n",
    "   test_df[i] = run_test(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72be703",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "306c8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predicted_ratings_leaderboard.txt', total, fmt='%d', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c017f1df2ec84156215240b0762243d8e283bbae2bf0907730c1f388e73998cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
